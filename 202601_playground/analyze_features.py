"""
íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë° ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì „ì²˜ë¦¬ ì „í›„ ë°ì´í„° ëª¨ë‘ ë¶„ì„ ê°€ëŠ¥
"""
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
except:
    try:
        plt.rcParams['font.family'] = 'AppleGothic'
        plt.rcParams['axes.unicode_minus'] = False
    except:
        pass

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ import
try:
    from modeling.train import prepare_data
except ImportError:
    print("âš ï¸ modeling.trainì—ì„œ prepare_dataë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    raise

try:
    from eda.dataload import load_data
except ImportError:
    print("âš ï¸ eda.dataloadì—ì„œ load_dataë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   ê¸°ë³¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def load_data():
        """ê¸°ë³¸ ë°ì´í„° ë¡œë“œ"""
        if os.path.exists('data/train.csv'):
            return pd.read_csv('data/train.csv'), pd.read_csv('data/test.csv'), pd.read_csv('data/sample_submission.csv')
        elif os.path.exists('../data/train.csv'):
            return pd.read_csv('../data/train.csv'), pd.read_csv('../data/test.csv'), pd.read_csv('../data/sample_submission.csv')
        else:
            raise FileNotFoundError("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def is_kaggle_environment():
    return os.path.exists('/kaggle/input')

# ë¶„ì„ í•¨ìˆ˜ë“¤
try:
    from eda.correlation_analysis import (
        calculate_correlation_matrix,
        plot_correlation_heatmap,
        find_high_correlations,
        calculate_vif,
        analyze_multicollinearity,
        plot_correlation_with_target
    )
except ImportError:
    print("âš ï¸ correlation_analysis.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   ì¸ë¼ì¸ìœ¼ë¡œ ë¶„ì„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ì¸ë¼ì¸ ë¶„ì„ í•¨ìˆ˜ë“¤ (ê°„ë‹¨ ë²„ì „)
    def calculate_correlation_matrix(X_train, method='pearson'):
        numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
        return X_train[numeric_cols].corr(method=method)
    
    def plot_correlation_heatmap(corr_matrix, figsize=(15, 12), save_path=None, title="íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ", threshold=None):
        plt.figure(figsize=figsize)
        mask = None
        if threshold is not None:
            mask = np.abs(corr_matrix) < threshold
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,
                   vmin=-1, vmax=1, square=True, linewidths=0.5, mask=mask)
        plt.title(title, fontsize=16, pad=20)
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… íˆíŠ¸ë§µ ì €ì¥: {save_path}")
        plt.show()
    
    def find_high_correlations(corr_matrix, threshold=0.7, exclude_diagonal=True):
        upper_triangle = corr_matrix.where(
            np.triu(np.ones(corr_matrix.shape), k=1 if exclude_diagonal else 0).astype(bool)
        )
        high_corr_pairs = []
        for col in upper_triangle.columns:
            for idx in upper_triangle.index:
                corr_value = upper_triangle.loc[idx, col]
                if pd.notna(corr_value) and abs(corr_value) >= threshold:
                    high_corr_pairs.append({
                        'Feature_1': idx,
                        'Feature_2': col,
                        'Correlation': corr_value,
                        'Abs_Correlation': abs(corr_value)
                    })
        if high_corr_pairs:
            return pd.DataFrame(high_corr_pairs).sort_values('Abs_Correlation', ascending=False)
        return pd.DataFrame(columns=['Feature_1', 'Feature_2', 'Correlation', 'Abs_Correlation'])
    
    def calculate_vif(X_train, target_col=None):
        try:
            from statsmodels.stats.outliers_influence import variance_inflation_factor
            if target_col and target_col in X_train.columns:
                X = X_train.drop(columns=[target_col])
            else:
                X = X_train.copy()
            numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
            X_numeric = X[numeric_cols].dropna()
            if len(X_numeric) == 0:
                return pd.DataFrame()
            vif_data = []
            for i in range(len(X_numeric.columns)):
                try:
                    vif_value = variance_inflation_factor(X_numeric.values, i)
                    vif_data.append({'Feature': X_numeric.columns[i], 'VIF': vif_value})
                except:
                    vif_data.append({'Feature': X_numeric.columns[i], 'VIF': np.nan})
            vif_df = pd.DataFrame(vif_data)
            def classify_multicollinearity(vif):
                if pd.isna(vif):
                    return 'ê³„ì‚° ë¶ˆê°€'
                elif vif < 5:
                    return 'ë‚®ìŒ (ì–‘í˜¸)'
                elif vif < 10:
                    return 'ë³´í†µ (ì£¼ì˜)'
                else:
                    return 'ë†’ìŒ (ë¬¸ì œ)'
            vif_df['Multicollinearity_Level'] = vif_df['VIF'].apply(classify_multicollinearity)
            return vif_df.sort_values('VIF', ascending=False, na_last=True)
        except ImportError:
            print("âš ï¸ statsmodelsê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install statsmodels")
            return pd.DataFrame()
    
    def analyze_multicollinearity(X_train, target_col=None, vif_threshold=10.0, corr_threshold=0.8):
        results = {}
        corr_matrix = calculate_correlation_matrix(X_train)
        high_corr = find_high_correlations(corr_matrix, threshold=corr_threshold)
        results['correlation_matrix'] = corr_matrix
        results['high_correlations'] = high_corr
        try:
            results['vif'] = calculate_vif(X_train, target_col)
        except:
            results['vif'] = None
        return results
    
    def plot_correlation_with_target(X_train, y_train, top_n=20, save_path=None):
        numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
        correlations = []
        for col in numeric_cols:
            corr = X_train[col].corr(y_train)
            correlations.append({'Feature': col, 'Correlation': corr, 'Abs_Correlation': abs(corr)})
        corr_df = pd.DataFrame(correlations).sort_values('Abs_Correlation', ascending=False).head(top_n)
        plt.figure(figsize=(10, max(8, len(corr_df) * 0.4)))
        colors = ['red' if x < 0 else 'blue' for x in corr_df['Correlation']]
        plt.barh(corr_df['Feature'], corr_df['Correlation'], color=colors)
        plt.xlabel('ìƒê´€ê³„ìˆ˜', fontsize=12)
        plt.title(f'íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ (ìƒìœ„ {top_n}ê°œ)', fontsize=14)
        plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        return corr_df


def analyze_preprocessed_data():
    """
    ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ìƒê´€ê´€ê³„ ë° ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„
    ì‹¤ì œ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹œ ë°ì´í„° ë¶„ì„
    """
    print("="*60)
    print("ğŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒê´€ê´€ê³„ ë¶„ì„")
    print("="*60)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = 'eda_results'
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    df_train, df_test, df_sub = load_data()
    
    # ì „ì²˜ë¦¬ (ëª¨ë¸ í•™ìŠµê³¼ ë™ì¼í•œ ê³¼ì •)
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    ENCODING_CONFIG = {
        'onehot_cols': ['gender', 'course', 'internet_access', 'study_method'],
        'ordinal_cols': ['exam_difficulty', 'facility_rating', 'sleep_quality'],
        'onehot_params': {'handle_unknown': 'ignore'},
        'ordinal_params': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1},
        'drop_original': True
    }
    
    X_train, y_train, X_test, categorical_cols, numeric_cols, encoder, encoded_cols_tag = prepare_data(
        df_train, df_test, 
        target_col='exam_score', 
        use_feature_engineering=True,
        encoding_config=ENCODING_CONFIG
    )
    
    print(f"\nğŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì´ íŠ¹ì„± ìˆ˜: {len(X_train.columns)}")
    print(f"   í•™ìŠµ ë°ì´í„° í¬ê¸°: {X_train.shape}")
    
    # 1. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ì „ì²˜ë¦¬ëœ ë°ì´í„°)
    print(f"\n{'='*60}")
    print("1ï¸âƒ£ ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
    print(f"{'='*60}")
    
    corr_matrix = calculate_correlation_matrix(X_train, method='pearson')
    print(f"   ìƒê´€ê´€ê³„ í–‰ë ¬ í¬ê¸°: {corr_matrix.shape}")
    
    # ì „ì²´ íˆíŠ¸ë§µ
    plot_correlation_heatmap(
        corr_matrix,
        figsize=(20, 16),
        save_path=f"{output_dir}/correlation_heatmap_preprocessed.png",
        title="ì „ì²˜ë¦¬ëœ ë°ì´í„° íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"
    )
    
    # 2. ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ
    print(f"\n{'='*60}")
    print("2ï¸âƒ£ ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ")
    print(f"{'='*60}")
    
    for threshold in [0.95, 0.9, 0.8, 0.7]:
        high_corr = find_high_correlations(corr_matrix, threshold=threshold)
        print(f"\n   |ìƒê´€ê³„ìˆ˜| >= {threshold}: {len(high_corr)}ê°œ ìŒ")
        if len(high_corr) > 0:
            print("   ìƒìœ„ 10ê°œ:")
            for idx, row in high_corr.head(10).iterrows():
                print(f"     {row['Feature_1']:30s} â†” {row['Feature_2']:30s}: {row['Correlation']:7.4f}")
    
    # ì €ì¥
    high_corr_all = find_high_correlations(corr_matrix, threshold=0.7)
    if len(high_corr_all) > 0:
        high_corr_all.to_csv(
            f"{output_dir}/high_correlations_preprocessed.csv", 
            index=False, 
            encoding='utf-8-sig'
        )
        print(f"\n   âœ… ì €ì¥: {output_dir}/high_correlations_preprocessed.csv")
    
    # 3. ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ (VIF)
    print(f"\n{'='*60}")
    print("3ï¸âƒ£ ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ (VIF)")
    print(f"{'='*60}")
    
    analysis_results = analyze_multicollinearity(X_train, target_col=None)
    
    if analysis_results.get('vif') is not None and len(analysis_results['vif']) > 0:
        vif_df = analysis_results['vif']
        vif_df.to_csv(
            f"{output_dir}/vif_preprocessed.csv", 
            index=False, 
            encoding='utf-8-sig'
        )
        print(f"   âœ… VIF ê²°ê³¼ ì €ì¥: {output_dir}/vif_preprocessed.csv")
        
        # ë†’ì€ VIF íŠ¹ì„± ì¶œë ¥
        high_vif = vif_df[vif_df['VIF'] >= 10]
        if len(high_vif) > 0:
            print(f"\n   âš ï¸ ë†’ì€ VIF íŠ¹ì„± (VIF >= 10): {len(high_vif)}ê°œ")
            for idx, row in high_vif.iterrows():
                print(f"     {row['Feature']:40s}: VIF = {row['VIF']:8.2f} ({row['Multicollinearity_Level']})")
        else:
            print("\n   âœ… VIF >= 10ì¸ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œê°€ ì ìŠµë‹ˆë‹¤.")
        
        # VIF ì‹œê°í™”
        plt.figure(figsize=(12, max(10, len(vif_df) * 0.25)))
        vif_sorted = vif_df.sort_values('VIF', ascending=True).tail(30)
        colors = ['green' if v < 5 else 'orange' if v < 10 else 'red' 
                 for v in vif_sorted['VIF']]
        plt.barh(vif_sorted['Feature'], vif_sorted['VIF'], color=colors)
        plt.xlabel('VIF (Variance Inflation Factor)', fontsize=12)
        plt.title('ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ - VIF (ìƒìœ„ 30ê°œ)', fontsize=14, pad=20)
        plt.axvline(x=5, color='orange', linestyle='--', linewidth=1.5, label='VIF = 5 (ì£¼ì˜)')
        plt.axvline(x=10, color='red', linestyle='--', linewidth=1.5, label='VIF = 10 (ë¬¸ì œ)')
        plt.legend(fontsize=10)
        plt.grid(axis='x', alpha=0.3)
        plt.tight_layout()
        plt.savefig(f"{output_dir}/vif_preprocessed.png", dpi=300, bbox_inches='tight')
        print(f"   âœ… VIF ê·¸ë˜í”„ ì €ì¥: {output_dir}/vif_preprocessed.png")
        plt.show()
    
    # 4. íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„
    print(f"\n{'='*60}")
    print("4ï¸âƒ£ íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„")
    print(f"{'='*60}")
    
    target_corr = plot_correlation_with_target(
        X_train, y_train, top_n=30,
        save_path=f"{output_dir}/target_correlation_preprocessed.png"
    )
    target_corr.to_csv(
        f"{output_dir}/target_correlations_preprocessed.csv", 
        index=False, 
        encoding='utf-8-sig'
    )
    print(f"   âœ… íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ì €ì¥: {output_dir}/target_correlations_preprocessed.csv")
    
    print(f"\nìƒìœ„ 10ê°œ íŠ¹ì„±:")
    for idx, row in target_corr.head(10).iterrows():
        print(f"   {row['Feature']:40s}: {row['Correlation']:7.4f}")
    
    # 5. ëª¨ë¸ë³„ íŠ¹ì„± êµ¬ì„± ë¶„ì„
    print(f"\n{'='*60}")
    print("5ï¸âƒ£ ëª¨ë¸ë³„ íŠ¹ì„± êµ¬ì„± ë¶„ì„")
    print(f"{'='*60}")
    
    encoded_cols = [col for col in X_train.columns if col.endswith(encoded_cols_tag)]
    
    # CatBoost íŠ¹ì„±
    catboost_features = [col for col in X_train.columns if col not in encoded_cols]
    print(f"\n   CatBoost ì‚¬ìš© íŠ¹ì„±: {len(catboost_features)}ê°œ")
    print(f"     - ì›ë³¸ ë²”ì£¼í˜• í¬í•¨: {len([c for c in categorical_cols if c in catboost_features])}ê°œ")
    print(f"     - ìˆ˜ì¹˜í˜• + FE íŠ¹ì„±: {len([c for c in catboost_features if c not in categorical_cols])}ê°œ")
    
    # LightGBM/XGBoost íŠ¹ì„±
    lgbm_xgb_features = [col for col in X_train.columns if col not in categorical_cols]
    print(f"\n   LightGBM/XGBoost ì‚¬ìš© íŠ¹ì„±: {len(lgbm_xgb_features)}ê°œ")
    print(f"     - Ordinal ì¸ì½”ë”©: {len(encoded_cols)}ê°œ")
    print(f"     - One-Hot ì¸ì½”ë”©: {len([c for c in lgbm_xgb_features if any(col in c for col in ENCODING_CONFIG.get('onehot_cols', []))])}ê°œ")
    print(f"     - ìˆ˜ì¹˜í˜• + FE íŠ¹ì„±: {len([c for c in lgbm_xgb_features if c not in encoded_cols and not any(col in c for col in ENCODING_CONFIG.get('onehot_cols', []))])}ê°œ")
    
    # ëª¨ë¸ë³„ ìƒê´€ê´€ê³„ ë¶„ì„
    print(f"\n   CatBoost íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
    catboost_corr = calculate_correlation_matrix(X_train[catboost_features])
    catboost_high_corr = find_high_correlations(catboost_corr, threshold=0.7)
    print(f"     ë†’ì€ ìƒê´€ê´€ê³„ (|r| >= 0.7): {len(catboost_high_corr)}ê°œ ìŒ")
    if len(catboost_high_corr) > 0:
        catboost_high_corr.to_csv(
            f"{output_dir}/catboost_high_correlations.csv",
            index=False,
            encoding='utf-8-sig'
        )
    
    print(f"\n   LightGBM/XGBoost íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
    lgbm_xgb_corr = calculate_correlation_matrix(X_train[lgbm_xgb_features])
    lgbm_xgb_high_corr = find_high_correlations(lgbm_xgb_corr, threshold=0.7)
    print(f"     ë†’ì€ ìƒê´€ê´€ê³„ (|r| >= 0.7): {len(lgbm_xgb_high_corr)}ê°œ ìŒ")
    if len(lgbm_xgb_high_corr) > 0:
        lgbm_xgb_high_corr.to_csv(
            f"{output_dir}/lgbm_xgb_high_correlations.csv",
            index=False,
            encoding='utf-8-sig'
        )
    
    print(f"\n{'='*60}")
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"   ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"{'='*60}")
    
    return {
        'correlation_matrix': corr_matrix,
        'high_correlations': high_corr_all,
        'vif': analysis_results.get('vif'),
        'target_correlations': target_corr
    }


if __name__ == "__main__":
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ì„ ì‹¤í–‰
    results = analyze_preprocessed_data()
