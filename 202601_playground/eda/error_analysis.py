"""
ì˜¤ì°¨ ë¶„ì„ ëª¨ë“ˆ - ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì‹ë³„ ë° ë¶„ì„
"""
import os
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from sklearn.metrics import mean_squared_error, mean_absolute_error

try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âš ï¸ matplotlib/seabornì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def find_high_error_samples(y_true: pd.Series, y_pred: np.ndarray, 
                            X_original: Optional[pd.DataFrame] = None,
                            top_n: int = 100, 
                            error_threshold: Optional[float] = None,
                            error_type: str = 'absolute') -> pd.DataFrame:
    """
    ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì‹ë³„
    
    Parameters:
    -----------
    y_true : pd.Series
        ì‹¤ì œ íƒ€ê²Ÿ ê°’
    y_pred : np.ndarray
        ì˜ˆì¸¡ ê°’
    X_original : pd.DataFrame, optional
        ì›ë³¸ íŠ¹ì„± ë°ì´í„° (ì €ì¥ìš©)
    top_n : int
        ìƒìœ„ Nê°œ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ (ê¸°ë³¸ê°’: 100)
    error_threshold : float, optional
        ì˜¤ì°¨ ì„ê³„ê°’ (ì´ ê°’ë³´ë‹¤ í° ìƒ˜í”Œë§Œ ì„ íƒ)
    error_type : str
        ì˜¤ì°¨ ê³„ì‚° ë°©ë²• ('absolute', 'squared', 'percentage')
        
    Returns:
    --------
    pd.DataFrame
        ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì •ë³´ (ì¸ë±ìŠ¤, ì‹¤ì œê°’, ì˜ˆì¸¡ê°’, ì˜¤ì°¨ ë“±)
    """
    # ì˜¤ì°¨ ê³„ì‚°
    if error_type == 'absolute':
        errors = np.abs(y_true.values - y_pred)
    elif error_type == 'squared':
        errors = (y_true.values - y_pred) ** 2
    elif error_type == 'percentage':
        errors = np.abs((y_true.values - y_pred) / (y_true.values + 1e-10)) * 100
    else:
        raise ValueError(f"Unknown error_type: {error_type}. Use 'absolute', 'squared', or 'percentage'")
    
    # ê²°ê³¼ DataFrame ìƒì„±
    error_df = pd.DataFrame({
        'index': y_true.index,
        'actual': y_true.values,
        'predicted': y_pred,
        'error': errors,
        'residual': y_true.values - y_pred
    })
    
    # ì˜¤ì°¨ ì„ê³„ê°’ í•„í„°ë§
    if error_threshold is not None:
        error_df = error_df[error_df['error'] >= error_threshold]
    
    # ìƒìœ„ Nê°œ ì„ íƒ
    error_df = error_df.nlargest(top_n, 'error').reset_index(drop=True)
    
    # ì›ë³¸ ë°ì´í„° ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
    if X_original is not None:
        # ì¸ë±ìŠ¤ë¡œ ì¡°ì¸
        error_df = error_df.merge(
            X_original.reset_index(),
            left_on='index',
            right_on='index',
            how='left'
        )
    
    return error_df


def analyze_high_error_samples(trainer, X_train: pd.DataFrame, y_train: pd.Series,
                               ensemble_pred: Optional[np.ndarray] = None,
                               top_n: int = 100,
                               error_threshold: Optional[float] = None,
                               save_dir: str = 'error_analysis_results'):
    """
    ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ë¶„ì„ ë° ì €ì¥
    
    Parameters:
    -----------
    trainer : ModelTrainer
        í•™ìŠµëœ ëª¨ë¸ì„ í¬í•¨í•œ ModelTrainer ê°ì²´
    X_train : pd.DataFrame
        í•™ìŠµ ë°ì´í„° (ì›ë³¸ íŠ¹ì„±)
    y_train : pd.Series
        íƒ€ê²Ÿ ë°ì´í„°
    ensemble_pred : np.ndarray, optional
        ì•™ìƒë¸” OOF ì˜ˆì¸¡ê°’ (ì—†ìœ¼ë©´ ê°œë³„ ëª¨ë¸ë³„ë¡œ ë¶„ì„)
    top_n : int
        ìƒìœ„ Nê°œ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ
    error_threshold : float, optional
        ì˜¤ì°¨ ì„ê³„ê°’ (RMSE ë‹¨ìœ„)
    save_dir : str
        ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
    --------
    dict
        ëª¨ë¸ë³„ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ë”•ì…”ë„ˆë¦¬
    """
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(save_dir).mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*60}")
    print("ğŸ“Š ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ë¶„ì„")
    print(f"{'='*60}")
    
    all_error_samples = {}
    
    # ì•™ìƒë¸” ì˜ˆì¸¡ì´ ìˆìœ¼ë©´ ì•™ìƒë¸” ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„
    if ensemble_pred is not None:
        print(f"\nğŸ” ì•™ìƒë¸” ëª¨ë¸ ì˜¤ì°¨ ë¶„ì„...")
        
        # ì•™ìƒë¸” ì˜¤ì°¨ ê³„ì‚°
        ensemble_rmse = np.sqrt(mean_squared_error(y_train, ensemble_pred))
        ensemble_mae = mean_absolute_error(y_train, ensemble_pred)
        
        print(f"   ì•™ìƒë¸” RMSE: {ensemble_rmse:.4f}")
        print(f"   ì•™ìƒë¸” MAE: {ensemble_mae:.4f}")
        
        # ì˜¤ì°¨ ì„ê³„ê°’ ì„¤ì • (ì—†ìœ¼ë©´ í‰ê·  + 2*í‘œì¤€í¸ì°¨)
        if error_threshold is None:
            errors = np.abs(y_train.values - ensemble_pred)
            error_threshold = np.mean(errors) + 2 * np.std(errors)
            print(f"   ìë™ ì„¤ì •ëœ ì˜¤ì°¨ ì„ê³„ê°’: {error_threshold:.4f}")
        
        # ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì°¾ê¸°
        error_samples = find_high_error_samples(
            y_train, ensemble_pred, X_original=X_train,
            top_n=top_n, error_threshold=error_threshold
        )
        
        all_error_samples['ensemble'] = error_samples
        
        # ì €ì¥
        csv_path = os.path.join(save_dir, 'high_error_samples_ensemble.csv')
        error_samples.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"   âœ… ì €ì¥: {csv_path} ({len(error_samples)}ê°œ ìƒ˜í”Œ)")
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        print(f"\n   ìƒìœ„ 10ê°œ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ:")
        for idx, row in error_samples.head(10).iterrows():
            print(f"     ìƒ˜í”Œ {row['index']:6d}: ì‹¤ì œ={row['actual']:6.2f}, ì˜ˆì¸¡={row['predicted']:6.2f}, ì˜¤ì°¨={row['error']:6.2f}")
    
    # ê°œë³„ ëª¨ë¸ë³„ ë¶„ì„
    for model_type in ['catboost', 'lightgbm', 'xgboost']:
        if model_type not in trainer.oof_predictions:
            continue
        
        print(f"\nğŸ” {model_type.upper()} ëª¨ë¸ ì˜¤ì°¨ ë¶„ì„...")
        
        oof_pred = trainer.oof_predictions[model_type]
        
        # ëª¨ë¸ë³„ ì˜¤ì°¨ ê³„ì‚°
        model_rmse = np.sqrt(mean_squared_error(y_train, oof_pred))
        model_mae = mean_absolute_error(y_train, oof_pred)
        
        print(f"   {model_type} RMSE: {model_rmse:.4f}")
        print(f"   {model_type} MAE: {model_mae:.4f}")
        
        # ì˜¤ì°¨ ì„ê³„ê°’ ì„¤ì •
        if error_threshold is None:
            errors = np.abs(y_train.values - oof_pred)
            threshold = np.mean(errors) + 2 * np.std(errors)
        else:
            threshold = error_threshold
        
        # ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì°¾ê¸°
        error_samples = find_high_error_samples(
            y_train, oof_pred, X_original=X_train,
            top_n=top_n, error_threshold=threshold
        )
        
        all_error_samples[model_type] = error_samples
        
        # ì €ì¥
        csv_path = os.path.join(save_dir, f'high_error_samples_{model_type}.csv')
        error_samples.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"   âœ… ì €ì¥: {csv_path} ({len(error_samples)}ê°œ ìƒ˜í”Œ)")
    
    # ì‹œê°í™”
    if VISUALIZATION_AVAILABLE and len(all_error_samples) > 0:
        print(f"\nğŸ“ˆ ì˜¤ì°¨ ë¶„ì„ ì‹œê°í™” ì¤‘...")
        _visualize_error_analysis(all_error_samples, y_train, save_dir)
    
    # ê³µí†µ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì°¾ê¸°
    if len(all_error_samples) > 1:
        _find_common_high_error_samples(all_error_samples, save_dir)
    
    print(f"\n{'='*60}")
    print(f"âœ… ì˜¤ì°¨ ë¶„ì„ ì™„ë£Œ!")
    print(f"   ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {save_dir}/")
    print(f"{'='*60}")
    
    return all_error_samples


def _visualize_error_analysis(all_error_samples: Dict[str, pd.DataFrame], 
                              y_train: pd.Series, save_dir: str):
    """ì˜¤ì°¨ ë¶„ì„ ì‹œê°í™”"""
    try:
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
        ax = axes[0, 0]
        for model_type, error_df in all_error_samples.items():
            ax.hist(error_df['error'], bins=30, alpha=0.5, label=model_type, density=True)
        ax.set_xlabel('Error', fontsize=12)
        ax.set_ylabel('Density', fontsize=12)
        ax.set_title('Error Distribution (High Error Samples)', fontsize=14)
        ax.legend()
        ax.grid(alpha=0.3)
        
        # 2. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„ (ì•™ìƒë¸”ë§Œ)
        if 'ensemble' in all_error_samples:
            ax = axes[0, 1]
            error_df = all_error_samples['ensemble']
            ax.scatter(error_df['actual'], error_df['predicted'], 
                      alpha=0.5, s=20, c=error_df['error'], cmap='Reds')
            ax.plot([y_train.min(), y_train.max()], 
                   [y_train.min(), y_train.max()], 'r--', lw=2)
            ax.set_xlabel('Actual', fontsize=12)
            ax.set_ylabel('Predicted', fontsize=12)
            ax.set_title('Actual vs Predicted (High Error Samples)', fontsize=14)
            ax.grid(alpha=0.3)
        
        # 3. ì”ì°¨ í”Œë¡¯
        if 'ensemble' in all_error_samples:
            ax = axes[1, 0]
            error_df = all_error_samples['ensemble']
            ax.scatter(error_df['predicted'], error_df['residual'], 
                      alpha=0.5, s=20)
            ax.axhline(y=0, color='r', linestyle='--', lw=2)
            ax.set_xlabel('Predicted', fontsize=12)
            ax.set_ylabel('Residual', fontsize=12)
            ax.set_title('Residual Plot (High Error Samples)', fontsize=14)
            ax.grid(alpha=0.3)
        
        # 4. ì˜¤ì°¨ í†µê³„ ë¹„êµ
        ax = axes[1, 1]
        model_names = []
        error_means = []
        error_stds = []
        for model_type, error_df in all_error_samples.items():
            model_names.append(model_type)
            error_means.append(error_df['error'].mean())
            error_stds.append(error_df['error'].std())
        
        x_pos = np.arange(len(model_names))
        ax.bar(x_pos, error_means, yerr=error_stds, alpha=0.7, capsize=5)
        ax.set_xticks(x_pos)
        ax.set_xticklabels(model_names)
        ax.set_ylabel('Mean Error', fontsize=12)
        ax.set_title('Error Statistics by Model', fontsize=14)
        ax.grid(alpha=0.3, axis='y')
        
        plt.tight_layout()
        plot_path = os.path.join(save_dir, 'error_analysis_visualization.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"   âœ… ì €ì¥: {plot_path}")
        plt.close()
    except Exception as e:
        print(f"   âš ï¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")


def _find_common_high_error_samples(all_error_samples: Dict[str, pd.DataFrame], save_dir: str):
    """ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ì°¾ê¸°"""
    print(f"\nğŸ” ê³µí†µ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ ë¶„ì„...")
    
    # ê° ëª¨ë¸ì˜ ìƒìœ„ ì˜¤ì°¨ ìƒ˜í”Œ ì¸ë±ìŠ¤
    error_indices_sets = {}
    for model_type, error_df in all_error_samples.items():
        # ìƒìœ„ 50ê°œë§Œ ê³ ë ¤
        top_indices = set(error_df.head(50)['index'].values)
        error_indices_sets[model_type] = top_indices
    
    # êµì§‘í•© ì°¾ê¸°
    if len(error_indices_sets) > 1:
        common_indices = set.intersection(*error_indices_sets.values())
        
        if len(common_indices) > 0:
            print(f"   ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œ: {len(common_indices)}ê°œ")
            
            # ê³µí†µ ìƒ˜í”Œ ì •ë³´ ìˆ˜ì§‘
            common_samples = []
            for idx in common_indices:
                sample_info = {'index': idx}
                for model_type, error_df in all_error_samples.items():
                    row = error_df[error_df['index'] == idx]
                    if len(row) > 0:
                        sample_info[f'{model_type}_error'] = row.iloc[0]['error']
                        sample_info[f'{model_type}_actual'] = row.iloc[0]['actual']
                        sample_info[f'{model_type}_predicted'] = row.iloc[0]['predicted']
                common_samples.append(sample_info)
            
            common_df = pd.DataFrame(common_samples)
            csv_path = os.path.join(save_dir, 'common_high_error_samples.csv')
            common_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"   âœ… ì €ì¥: {csv_path}")
        else:
            print(f"   ê³µí†µ ì˜¤ì°¨ê°€ í° ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"   ëª¨ë¸ì´ 1ê°œë¿ì´ì–´ì„œ ê³µí†µ ìƒ˜í”Œ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
