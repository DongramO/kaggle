import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from catboost import CatBoostClassifier
import lightgbm as lgb
import xgboost as xgb
from scipy.optimize import minimize
from sklearn.metrics import log_loss
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
 
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix
 
import optuna
from sklearn.model_selection import StratifiedKFold, cross_val_score
 
# ìƒëŒ€ ê²½ë¡œ ì‚¬ìš© (ê°™ì€ í´ë”ì— ìˆëŠ” íŒŒì¼ ì°¸ì¡°)
df_train = pd.read_csv('train.csv')
df_test = pd.read_csv('test.csv')
df_sub = pd.read_csv('sample_submission.csv')

optuna.logging.set_verbosity(optuna.logging.WARNING)

def eda(df_train, df_test, df_sub):
    print(df_train.head())
    
    print('df_train.shape', df_train.shape)
    print('df_test.shape', df_test.shape)
    
    print(df_train.info())
    print(df_test.info())
    print(df_train.describe())
    
    
    print('df_train.shape:', df_train.shape)
    print('df_test.shape:', df_test.shape)
    
    
    print(df_train.info())
    print(df_test.info())
    print(df_train.describe())
    
    cols = ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score',
        'loan_amount', 'interest_rate', 'gender', 'marital_status',
        'education_level', 'employment_status', 'loan_purpose',
        'grade_subgrade', 'loan_paid_back']
    
    for col in cols:
        print(col, df_train[col].nunique())
    
    
    num_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']

    cat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']
    
    # Target Distribution Visualization
    counts = df_train['loan_paid_back'].value_counts()
    labels = counts.index
    values = counts.values
    
    plt.figure(figsize=(15,5.5))
    
    bars = plt.barh(labels, values, color = 'crimson')
    plt.ylabel("loan_paid_back")
    plt.xlabel("Frequency")
    plt.title("The Distribution of the Target Column 'loan_paid_back'")
    plt.yticks([1, 0])
    
    total = values.sum()
    for bar, count in zip(bars, values):
        width = bar.get_width()
        pct = count / total * 100
        plt.text(width, bar.get_y() + bar.get_height()/2,
                f"{count}\n({pct:.1f}%)",
                ha='left', va='center')
    # plt.show()
    
    
    # Data dirtribution visualization
    n_vars = len(num_cols)
    fig, axes = plt.subplots(n_vars, 2, figsize=(12, n_vars*3))
    for i, col in enumerate(num_cols):
        axes[i,0].hist(df_train[col], bins=50, edgecolor='black', color='crimson')
        axes[i,0].set_title(f'{col} histogram')
        axes[i,1].boxplot(df_train[col], vert=False)
        axes[i,1].set_title(f'{col} boxplot')
    
    plt.tight_layout()
    # plt.show()
    
    
    # outliers
    
    n_vars = len(num_cols)
    n_cols = 2
    n_rows = (n_vars + 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_vars * 3))
    
    for i, col in enumerate(num_cols):
        row = i // 2
        col_idx = i % 2
        sns.boxplot(x='loan_paid_back', y=col, data=df_train, ax=axes[row, col_idx], palette='pastel')
        axes[row, col_idx].set_title(f'{col} by loan_paid_back')
    
    if n_vars % 2 !=0:
        fig.delaxes(axes[n_rows-1, 1])
    
    plt.tight_layout()
    # plt.show()
    
    
    
    n_vars = len(cat_cols)
    fig, axes = plt.subplots(n_vars, 2, figsize=(14, n_vars*8))
    
    for i, col in enumerate(cat_cols):
        sns.countplot(x=df_train[col], ax=axes[i,0], order=df_train[col].value_counts().index, palette='pastel')
        axes[i,0].set_title(f'{col} countplot')
        axes[i,0].set_xlabel('')
        axes[i,0].set_ylabel('Count')
        axes[i,0].tick_params(axis='x', rotation=45)
    
        df_train[col].value_counts().plot.pie(
            ax=axes[i, 1],
            autopct='%1.1f%%',
            startangle=90,
            colors=sns.color_palette('pastel'),
            legend=False,
            ylabel=''
        )
        axes[i,1].set_title(f'{col} Pie chart')
    
    plt.tight_layout()
    # plt.show()
    
    n_vars = len(cat_cols)
    n_cols = 2
    n_rows = (n_vars + 1) // 2
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5 * n_rows))
    
    for i, col in enumerate(cat_cols):
        row  = i // 2
        col_idx = i % 2
        sns.countplot(x=col, hue='loan_paid_back', data=df_train, ax=axes[row, col_idx], palette='pastel')
        axes[row, col_idx].set_title(f"{col} by loan_paid_back")
        axes[row, col_idx].tick_params(axis='x', rotation=45)
        axes[row, col_idx].set_xlabel(col)
        axes[row, col_idx].set_ylabel('Count')
    
    if n_vars % 2 != 0:
        fig.delaxes(axes[n_rows - 1, 1])
    
    plt.tight_layout()
    # plt.show()
    
    
    n_vars = len(cat_cols)
    n_cols = 2
    n_rows = (n_vars + 1) // 2
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5 * n_rows))
    
    for i, col in enumerate(cat_cols):
        row = i // 2
        col_idx = i % 2
    
        ratio = (
            df_train.groupby(col)['loan_paid_back']
            .value_counts(normalize=True)
            .rename('ratio')
            .mul(100)
            .reset_index()
        )
    
        ratio = ratio[ratio['loan_paid_back'] == 0]
    
        sns.barplot(
            data=ratio,
            x=col,
            y='ratio',
            ax=axes[row, col_idx],
            palette='pastel'
        )
    
        axes[row, col_idx].set_title(f"{col}: % Not Paid Back")
        axes[row, col_idx].set_xlabel(col)
        axes[row, col_idx].set_ylabel('% Not Paid Back')
        axes[row, col_idx].tick_params(axis='x', rotation=45)
        axes[row, col_idx].bar_label(axes[row, col_idx].containers[0], fmt='%.1f%%', label_type='edge', fontsize=9)
    
    if n_vars % 2 != 0:
        fig.delaxes(axes[n_rows - 1, 1])
    
    plt.tight_layout()
    # plt.show()

rs = 42
model_types = ["catboost", "lgbm", "xgb"]

def data_preprocessing(df_array, target_col, df_num_cols, df_cat_cols):
    
    def log_regularization(df_array):
        
        for df in df_array:

            df["loan_amount"] = np.log1p(df["loan_amount"])
            df["interest_rate"] = np.log1p(df["interest_rate"])
            df["annual_income"] = np.log1p(df["annual_income"])    
        
        return df_array
    
    def remove_outliers(df_array, cols):

        for df in df_array:

            for col in cols:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3- Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR

                # lowerì™€ upperë¥¼ êµ¬í•˜ê³  ì‚¬ì´ì˜ ê°’ì„ ì‚¬ìš©í•¨ ì •ìƒì ì¸ ê°’ë“¤ë§Œ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” ì˜ì§€
                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
                
        return df_array

    def feature_engineering(df_array):
        
        eps = 1e-6
        
        for df in df_array:
            # 1. interest_rate / debt_to_income_ratio
            df["interest_rate_to_dti"] = df["interest_rate"] / (df["debt_to_income_ratio"] + eps)
            
            # 2. education_level & loan_purpose
            df["loan_purpose_interest_rate"] = df["loan_purpose"].astype(str) + "_" + np.log1p(df["interest_rate"].round(1)).astype(str)
            
            # 3. employment_status & loan_purpose
            df['employment_status_grade_subgrade'] = df['employment_status'].astype(str) + '_' + df['grade_subgrade'].astype(str)
            df["employment_loan_purpose"] = df["employment_status"].astype(str) + "_" + df["loan_purpose"].astype(str)
            df["education_loan_purpose"] = df["education_level"].astype(str) + "_" + df["loan_purpose"].astype(str)

            # 4. monthly_income 
            df["monthly_income"] = df["annual_income"] / 12
            df["debt_to_monthly_income"] = df["debt_to_income_ratio"] / (df["monthly_income"] + eps)
            # df["monthly_income_interest_amount"] = df["monthly_income"] / ( df["interest_rate"] * df["loan_amount"] / 12)
            df["estimated_monthly_payment"] = (df["loan_amount"] * df["interest_rate"]) / 12
            df["pti_ratio"] = df["estimated_monthly_payment"] / (df["monthly_income"] + eps)
            
            # 5. education_level & grade_subgrade
            # df["education_grade_subgrade"] = df["education_level"].astype(str) + "_" + df["grade_subgrade"].astype(str)
            df["head_grade"] = df["grade_subgrade"].astype(str).str.split('_').str[0]
            
            # 6. loan_amount_div
            df["loan_amount_credit"] = df["loan_amount"].astype(float) / (df["credit_score"].astype(float)+ eps)
            df["loan_amount_div_income"] = df["loan_amount"].astype(int) / (df["annual_income"].astype(float)+ eps)
            df["loan_amount_div_ratio"] = df["loan_amount"].astype(float) / (df["debt_to_income_ratio"].astype(float)+ eps)
            
            # 7. creadit
            df["credit_div_ratio"] = df["credit_score"].astype(float) / (df["debt_to_income_ratio"].astype(float)+ eps)

    
        return df_array

    # df_array = log_regularization(df_array)
    df_array = feature_engineering(df_array)
    # df_array = remove_outliers(df_array, df_num_cols)
    return df_array

def encoding_data(df_train, target_col, model_type, X, y,X_train, X_val, y_train, y_val):

    df_num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    df_cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    

    # ìˆœì„œê°€ ì—†ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ onehot encoding
    onehot_cols = [
                    'gender',
                    'marital_status',
                    'loan_purpose',
                #    'employment_loan_purpose',
                #    'education_loan_purpose',
                ]
    
    # ìˆœì„œê°€ ìˆëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ ordinal encoding
    ordinal_cols = [
                    'education_level',
                    'employment_status',
                    'grade_subgrade',
                    'head_grade',
                    'employment_status_grade_subgrade',
                    ]
    
    num_transformer = StandardScaler()
    onehot_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
    ordinal_transformer = OrdinalEncoder()
    
    preprocessor_list = []
    preprocessor = None
    if model_type == "catboost":
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', num_transformer, df_num_cols),
                # ('cat', onehot_transformer, onehot_cols),
                # ('ordinal', ordinal_transformer, ordinal_cols)
            ],
            remainder='drop'  
        )
    elif model_type == "lgbm":
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', num_transformer, df_num_cols),
                # ('onehot', onehot_transformer, onehot_cols),
                ('ordinal', ordinal_transformer, ordinal_cols)
            ],
            remainder='drop'  
        )
    elif model_type == "xgb":
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', num_transformer, df_num_cols),
                # ('onehot', onehot_transformer, onehot_cols),
                # ('ordinal', ordinal_transformer, ordinal_cols)
            ],
            remainder='drop'  
        )
    else:
        raise ValueError(f"Invalid model type: {model_type}")
                                
    X_train_processed = preprocessor.fit_transform(X_train)
    X_val_processed = preprocessor.transform(X_val)
    
    

    return [X_train_processed, X_val_processed, y_train, y_val, preprocessor]


def optimize_models(X_train, y_train, model_type):
    def objective(trial):
        # model_type = trial.suggest_categorical("model", ["logistic", "lgbm", "xgb"])
        
        if model_type == "catboost":
            params = {
                "iterations": trial.suggest_int("iterations", 100, 500),
                "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1, 100.0, log=True),
                "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.1, log=True),
                "random_strength": trial.suggest_float("random_strength", 0.0, 1.0),
                "depth": trial.suggest_int("depth", 4, 10),
                "random_seed": rs,
                "loss_function": "Logloss",      # 2ì§„ ë¶„ë¥˜ ê¸°ë³¸
                "eval_metric": "AUC",            # ëª¨ë‹ˆí„°ë§í•  ì§€í‘œ
                "verbose": False,   
            }
            model = CatBoostClassifier(**params)
        
        elif model_type == "lgbm":
            params = {
                "n_estimators": trial.suggest_int("n_estimators", 100, 800),
                "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.05, log=True),
                "num_leaves": trial.suggest_int("num_leaves", 31, 255),
                "max_depth": trial.suggest_int("max_depth", 4, 15),
                "subsample": trial.suggest_float("subsample", 0.6, 1.0),
                "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
                "reg_alpha": trial.suggest_float("reg_alpha", 1e-3, 10.0, log=True),
                "reg_lambda": trial.suggest_float("reg_lambda", 1e-3, 10.0, log=True),
                "random_state": rs,
                "verbose": -1,
            }
            model = lgb.LGBMClassifier(**params)
        
        else:  # XGBoost
            params = {
                "n_estimators": trial.suggest_int("n_estimators", 300, 800),
                "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.05, log=True),
                "max_depth": trial.suggest_int("max_depth", 3, 12),
                "subsample": trial.suggest_float("subsample", 0.6, 1.0),
                "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
                "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
                "gamma": trial.suggest_float("gamma", 0.0, 1.0),
                "reg_alpha": trial.suggest_float("reg_alpha", 1e-3, 10.0, log=True),
                "reg_lambda": trial.suggest_float("reg_lambda", 1e-3, 10.0, log=True),
                "random_state": rs,
                # "use_label_encoder": False,
                "eval_metric": "auc",
            }
            model = xgb.XGBClassifier(**params)
        
        # k-foldë¥¼ í†µí•´ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ê°ì²´ ìƒì„±
        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=rs)
        
        # êµì°¨ ê²€ì¦ì„ í†µí•´ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        scores = cross_val_score(model, X_train, y_train, cv=cv, scoring="roc_auc", n_jobs=-1)
        return np.mean(scores)

    # optunaë¥¼ í†µí•´ ìµœì ì˜ íŒŒë¼ë©”í„°ë¥¼ ì°¾ì•„ê°€ëŠ” ê³¼ì •
    sampler = optuna.samplers.TPESampler(seed=rs)
    study = optuna.create_study(direction="maximize", sampler=sampler)
    # ì‹¤ì œë¡œ ëª¨ë¸ì„ ëŒë ¤ë³´ë©´ì„œ ìµœì ì˜ íŒŒë¼ë©”í„°ë¥¼ ì°¾ëŠ” ê³¼ì •
    study.optimize(objective, n_trials=50)
    
    print("\nBest trial:" , model_type)
    print(study.best_trial.params)
    return study.best_trial.params

def create_models_with_optuna(X_train, y_train, model_type, use_fixed_params):
    """Optuna ìµœì í™” ë˜ëŠ” ê³ ì • íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìƒì„±"""
    if use_fixed_params:
        # ê³ ì • íŒŒë¼ë¯¸í„° ì‚¬ìš©
        if model_type == "catboost":
            fixed_params = {
                "loss_function": "Logloss",
                "eval_metric": "AUC",
                "iterations": 475,
                "learning_rate": 0.09983620901362981,
                'l2_leaf_reg': 15.332725842146589,
                'random_strength': 0.7485180520264623,
                "depth": 7,
                "random_seed": rs,
                "verbose": False,
            }
            model = CatBoostClassifier(**fixed_params)
            
        elif model_type == "lgbm":
            fixed_params = {
                "colsample_bytree": 0.5295722198581925,
                "learning_rate": 0.04919972117020984,
                "max_depth": 8,
                "n_estimators": 576,
                "num_leaves": 93,
                "reg_alpha": 9.320749906598678,
                "reg_lambda": 0.045393254289234894,
                "subsample": 0.8368214696612971,
                "random_state": rs,
                "verbose": -1,
            }
            model = lgb.LGBMClassifier(**fixed_params)
            
        elif model_type == "xgb":
            fixed_params = {
                "colsample_bytree": 0.9738845151688945,
                "gamma": 0.6097633807345567,
                "learning_rate": 0.03398329815843991,
                "max_depth": 7,
                "min_child_weight": 5,
                "n_estimators": 690,
                "reg_alpha": 4.931603458294555,
                "reg_lambda": 0.14289737491259996,
                "subsample": 0.7574655551921472,
                "random_state": rs,
                "eval_metric": "auc",
            }
            model = xgb.XGBClassifier(**fixed_params)
            
        print(f"âœ… {model_type.upper()} ëª¨ë¸ ìƒì„± ì™„ë£Œ (ê³ ì • íŒŒë¼ë¯¸í„° ì‚¬ìš©)")
        return model
    
    else:
        try:
            print(f"\nğŸš€ {model_type.upper()} ìµœì í™” ì‹œì‘...")
            best_params = optimize_models(X_train, y_train, model_type)
            
            # ìµœì  íŒŒë¼ë¯¸í„° ì¬í™•ì¸ ì¶œë ¥
            print(f"âœ… {model_type.upper()} ìµœì¢… ì‚¬ìš© íŒŒë¼ë¯¸í„°:")
            print("-" * 80)
            for key, value in sorted(best_params.items()):
                print(f"  {key:25s}: {value}")
            print("-" * 80)
            
            # ëª¨ë¸ ìƒì„±
            if model_type == "catboost":
                model = CatBoostClassifier(**best_params)
            elif model_type == "lgbm":
                model = lgb.LGBMClassifier(**best_params)
            elif model_type == "xgb":
                model = xgb.XGBClassifier(**best_params)
            
            print(f"âœ… {model_type.upper()} ëª¨ë¸ ìƒì„± ì™„ë£Œ\n")
            return model
            
        except Exception as e:
            print(f"\nâŒ {model_type.upper()} ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            raise

def find_optimal_weights(models, preprocessor_list):
    """ê° ëª¨ë¸ë³„ ì „ì²˜ë¦¬ëœ validation setì„ ì‚¬ìš©í•˜ì—¬ optimal weights ì°¾ê¸°"""
    
    cb_model = models['catboost']
    lgb_model = models['lgbm']
    xgb_model = models['xgb']
    
    # ê° ëª¨ë¸ì˜ ì „ì²˜ë¦¬ëœ validation set ê°€ì ¸ì˜¤ê¸°
    # preprocessor_list êµ¬ì¡°: [X_train, X_val, y_train, y_val, preprocessor]
    X_val_catboost = preprocessor_list[0][1]  # catboostìš© ì „ì²˜ë¦¬ëœ validation set
    X_val_lgbm = preprocessor_list[1][1]      # lgbmìš© ì „ì²˜ë¦¬ëœ validation set
    X_val_xgb = preprocessor_list[2][1]       # xgbìš© ì „ì²˜ë¦¬ëœ validation set
    y_val = preprocessor_list[0][3]           # ëª¨ë“  ëª¨ë¸ì˜ y_valì€ ë™ì¼
    
    # ê° ëª¨ë¸ì— ë§ëŠ” ì „ì²˜ë¦¬ëœ validation setìœ¼ë¡œ ì˜ˆì¸¡
    cb_pred = cb_model.predict_proba(X_val_catboost)[:, 1]
    lgb_pred = lgb_model.predict_proba(X_val_lgbm)[:, 1]
    xgb_pred = xgb_model.predict_proba(X_val_xgb)[:, 1]
    
    preds = np.vstack([cb_pred, lgb_pred, xgb_pred]).T  # shape: (N, 3)

    # ì´ˆê¸°ê°’ (ê· ë“±ë¶„ë°°)
    init_w = np.array([1/3, 1/3, 1/3])

    # ì œì•½ì¡°ê±´: w >= 0, sum(w)=1
    constraints = ({
        'type': 'eq',
        'fun': lambda w: np.sum(w) - 1
    })
    min_w = 0.1
    bounds = [(min_w, 1)] * 3

    # ëª©ì  í•¨ìˆ˜: logloss ìµœì†Œí™”
    def loss_fn(w):
        blended = np.dot(preds, w)
        return log_loss(y_val, blended)

    result = minimize(loss_fn, init_w, method='SLSQP',
                      bounds=bounds, constraints=constraints)

    optimal_w = result.x
    print(f"Optimal weights - CatBoost: {optimal_w[0]:.4f}, LightGBM: {optimal_w[1]:.4f}, XGBoost: {optimal_w[2]:.4f}")
    return optimal_w

def ensemble_predict(models, preprocessed_X_list, weights):
    """ê° ëª¨ë¸ë³„ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ensemble ì˜ˆì¸¡"""
    cb_model = models['catboost']
    lgb_model = models['lgbm']
    xgb_model = models['xgb']
    
    X_catboost = preprocessed_X_list[0]  # catboostìš© ì „ì²˜ë¦¬ëœ ë°ì´í„°
    X_lgbm = preprocessed_X_list[1]      # lgbmìš© ì „ì²˜ë¦¬ëœ ë°ì´í„°
    X_xgb = preprocessed_X_list[2]       # xgbìš© ì „ì²˜ë¦¬ëœ ë°ì´í„°
    
    # ê° ëª¨ë¸ì— ë§ëŠ” ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ì˜ˆì¸¡
    # predict_probaê°€ 1ì°¨ì› ë°°ì—´ì„ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    def safe_predict_proba(model, X):
        """predict_proba ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (1ì°¨ì› ë˜ëŠ” 2ì°¨ì› ë°°ì—´ ëª¨ë‘ ì§€ì›)"""
        proba = model.predict_proba(X)
        if proba.ndim == 1:
            # 1ì°¨ì› ë°°ì—´ì¸ ê²½ìš° (CatBoost ë“±ì—ì„œ ë°œìƒ ê°€ëŠ¥)
            return proba
        elif proba.ndim == 2 and proba.shape[1] > 1:
            # 2ì°¨ì› ë°°ì—´ì´ê³  í´ë˜ìŠ¤ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°
            return proba[:, 1]  # ì–‘ì„± í´ë˜ìŠ¤ í™•ë¥ 
        else:
            # 2ì°¨ì›ì´ì§€ë§Œ í´ë˜ìŠ¤ê°€ 1ê°œì¸ ê²½ìš°
            return proba.flatten()
    
    cb_pred = safe_predict_proba(cb_model, X_catboost)
    lgb_pred = safe_predict_proba(lgb_model, X_lgbm)
    xgb_pred = safe_predict_proba(xgb_model, X_xgb)
    
    preds = np.vstack([cb_pred, lgb_pred, xgb_pred]).T
    ensemble_pred_proba = np.dot(preds, weights)
    ensemble_pred = (ensemble_pred_proba >=0.5).astype(float)
    
    return ensemble_pred, ensemble_pred_proba

def train_catboost(model, X_train, X_val, y_train, y_val):
    
    possible_cat_cols = [
        'gender', 'marital_status', 'education_level', 'employment_status',
        'loan_purpose', 'grade_subgrade', 'head_grade',
        'employment_status_grade_subgrade',
        'loan_purpose_interest_rate',
        'employment_status_grade_subgrade',
        'employment_loan_purpose',
        'education_loan_purpose',
        'head_grade'
    ]
    cat_cols = [col for col in possible_cat_cols if col in X_train.columns]
    
    # model = CatBoostClassifier(
    #     loss_function='Logloss',
    #     eval_metric='AUC',
    #     random_seed=rs,
    #     verbose=False
    # )
    
    model.fit(
        X_train,
        y_train,
        cat_features=cat_cols,          # ì—¬ê¸°ì„œë§Œ cat_features ì‚¬ìš©
        eval_set=(X_val, y_val),
        use_best_model=True
    )
    
    return model

def main(df_array, target_col, num_cols, cat_cols):
    
    df_array = data_preprocessing(df_array, target_col, num_cols, cat_cols)
    
    df_train = df_array[0]
    df_test = df_array[1]
    
    model_types = ["catboost", "lgbm", "xgb"]

    
    X = df_train.drop(columns=[target_col])
    y = df_train[target_col]
    
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rs)
    
    preprocessor_list = []
    preprocessor_list.append(encoding_data(df_train, target_col, model_types[1], X, y, X_train, X_val, y_train, y_val))
    preprocessor_list.append(encoding_data(df_train, target_col, model_types[2], X, y, X_train, X_val, y_train, y_val))
    
    model_result = []
    cb_model = create_models_with_optuna(X_train, y_train, model_type=model_types[0], use_fixed_params=True)
    cb_model_trained = train_catboost(cb_model, X_train, X_val, y_train, y_val)
    model_result.append(cb_model_trained)
    
    for idx, preprocessor in enumerate(preprocessor_list):
        
        X_train_processed = preprocessor[0]
        X_val_processed = preprocessor[1]
        y_train = preprocessor[2]
        y_val = preprocessor[3]
        preprocessor = preprocessor[4]
        
        print("ğŸ” Optimizing models with Optuna...")
        
        processed_model = create_models_with_optuna(X_train_processed, y_train, model_type=model_types[idx+1], use_fixed_params=True)

        feature_names = preprocessor.get_feature_names_out()
        X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)
        X_val_df = pd.DataFrame(X_val_processed, columns=feature_names)
        
        if model_types[idx+1] == "lgbm":
            processed_model.fit(
                X_train_df, y_train,
                eval_set=[(X_val_df, y_val)],
                callbacks=[
                    lgb.early_stopping(stopping_rounds=100),
                    lgb.log_evaluation(0)
                ]
            )
        elif model_types[idx+1] == "xgb":
            processed_model.fit(
                X_train_processed, y_train,
                eval_set=[(X_val_processed, y_val)],
                verbose=False
            )
        model_result.append(processed_model)
    
    models = {
        'lgbm': model_result[0],
        'xgb': model_result[1],
        'catboost': model_result[2],
    }
    preprocessor_list.append([X_train, X_val, y_train, y_val, cb_model])
    
    
    for idx, (name, model) in enumerate(models.items()):
        X_val_data = preprocessor_list[idx][1]  # validation set
        y_val_data = preprocessor_list[idx][3]  # validation labels
        
        try:
            pred = model.predict(X_val_data)
            proba = model.predict_proba(X_val_data)[:, 1]
            
            acc = accuracy_score(y_val_data, pred)
            auc = roc_auc_score(y_val_data, proba)
            print(f"{name} - Accuracy: {acc:.4f}, AUC: {auc:.4f}")
        except Exception as e:
            print(f"{name} - Error: {e}")
            import traceback
            traceback.print_exc()

    try:
        # ê° ëª¨ë¸ì˜ ì „ì²˜ë¦¬ëœ validation set ê°€ì ¸ì˜¤ê¸°
        X_val_list = [preprocessor_list[i][1] for i in range(3)]  # [catboost, lgbm, xgb]
        y_val = preprocessor_list[0][3]  # ëª¨ë“  ëª¨ë¸ì˜ y_valì€ ë™ì¼
        
        # model_result ëŒ€ì‹  models ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
        weights = find_optimal_weights(models, preprocessor_list)
        ensemble_pred, ensemble_pred_proba = ensemble_predict(models, X_val_list, weights)
        ensemble_acc = accuracy_score(y_val, ensemble_pred)
        ensemble_auc = roc_auc_score(y_val, ensemble_pred_proba)
        print(f"Ensemble - Accuracy: {ensemble_acc:.4f}, AUC: {ensemble_auc:.4f}")
    except Exception as e:
        print(f"Ensemble Error: {e}")
    
    return preprocessor_list, models

def analyze_model_performance(models, X_val, y_val, model_names=None):
    """ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    if model_names is None:
        model_names = list(models.keys())
    
    print("\n" + "="*80)
    print("ğŸ“Š ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ")
    print("="*80)
    
    for name in model_names:
        if name not in models:
            continue
            
        model = models[name]
        y_pred = model.predict(X_val)
        y_pred_proba = model.predict_proba(X_val)[:, 1]
        
        acc = accuracy_score(y_val, y_pred)
        auc = roc_auc_score(y_val, y_pred_proba)
        
        print(f"\nğŸ”¹ {name} ëª¨ë¸")
        print(f"   Accuracy: {acc:.4f}")
        print(f"   ROC-AUC:  {auc:.4f}")
        print("\n   Classification Report:")
        print(classification_report(y_val, y_pred, target_names=['Not Paid', 'Paid']))
        print("\n   Confusion Matrix:")
        cm = confusion_matrix(y_val, y_pred)
        print(f"   [[{cm[0,0]:5d}  {cm[0,1]:5d}]")
        print(f"    [{cm[1,0]:5d}  {cm[1,1]:5d}]]")

def get_feature_importance(model, feature_names, model_name):
    """ëª¨ë¸ë³„ feature importanceë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    importance_dict = {}
    
    if model_name == 'catboost' or isinstance(model, CatBoostClassifier):
        # CatBoost
        importance = model.get_feature_importance()
        importance_dict = dict(zip(feature_names, importance))
        
    elif model_name == 'LightGBM' or isinstance(model, lgb.LGBMClassifier):
        # LightGBM
        importance = model.feature_importances_
        importance_dict = dict(zip(feature_names, importance))
        
    elif model_name == 'XGBoost' or isinstance(model, xgb.XGBClassifier):
        # XGBoost
        importance = model.feature_importances_
        importance_dict = dict(zip(feature_names, importance))
    
    return importance_dict

def visualize_feature_importance(models, feature_names, top_n=30, figsize=(15, 10)):
    """ëª¨ë¸ë³„ feature importanceë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    n_models = len(models)
    fig, axes = plt.subplots(n_models, 1, figsize=figsize)
    
    if n_models == 1:
        axes = [axes]
    
    for idx, (name, model) in enumerate(models.items()):
        importance_dict = get_feature_importance(model, feature_names, name)
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
        top_features = sorted_importance[:top_n]
        
        features = [f[0] for f in top_features]
        importances = [f[1] for f in top_features]
        
        # ì‹œê°í™”
        axes[idx].barh(range(len(features)), importances, color='crimson')
        axes[idx].set_yticks(range(len(features)))
        axes[idx].set_yticklabels(features)
        axes[idx].set_xlabel('Feature Importance')
        axes[idx].set_title(f'{name} - Top {top_n} Feature Importance')
        axes[idx].invert_yaxis()
        
        # ê°’ í‘œì‹œ
        for i, v in enumerate(importances):
            axes[idx].text(v, i, f' {v:.2f}', va='center')
    
    plt.tight_layout()
    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
    print("\nâœ… Feature importance ì‹œê°í™”ê°€ 'feature_importance.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # plt.show()

def compare_feature_importance(models, feature_names, top_n=15):
    """ëª¨ë¸ë³„ feature importanceë¥¼ ë¹„êµí•˜ëŠ” í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ“ˆ ëª¨ë¸ë³„ Feature Importance ë¹„êµ (Top {} features)".format(top_n))
    print("="*80)
    
    all_importances = {}
    
    for name, model in models.items():
        importance_dict = get_feature_importance(model, feature_names, name)
        sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ”¹ {name} - Top {top_n} Features:")
        print("-" * 80)
        for i, (feature, importance) in enumerate(sorted_importance[:top_n], 1):
            print(f"  {i:2d}. {feature:40s} : {importance:10.4f}")
            if feature not in all_importances:
                all_importances[feature] = {}
            all_importances[feature][name] = importance
    
    # í†µí•© ë¹„êµ ì‹œê°í™”
    common_features = set()
    for name in models.keys():
        importance_dict = get_feature_importance(models[name], feature_names, name)
        sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
        top_features = [f[0] for f in sorted_importance[:top_n]]
        if not common_features:
            common_features = set(top_features)
        else:
            common_features = common_features.intersection(set(top_features))
    
    if common_features:
        print(f"\nğŸ”¹ ê³µí†µ ì¤‘ìš” Feature (ëª¨ë“  ëª¨ë¸ì—ì„œ Top {top_n}ì— í¬í•¨):")
        print("-" * 80)
        for feature in sorted(common_features):
            print(f"  - {feature}")

def save_model_analysis(models, X_val, y_val, feature_names, preprocessor, 
                        num_cols, onehot_cols, ordinal_cols, filename='model_analysis.txt'):
    """ëª¨ë¸ ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ëª¨ë¸ ìƒì„¸ ë¶„ì„ ê²°ê³¼\n")
        f.write("="*80 + "\n\n")
        
        # Feature ì´ë¦„ ì •ë³´
        f.write("ğŸ“‹ ì‚¬ìš©ëœ Feature ëª©ë¡:\n")
        f.write("-" * 80 + "\n")
        f.write(f"ìˆ˜ì¹˜í˜• Feature ({len(num_cols)}ê°œ): {', '.join(num_cols)}\n")
        f.write(f"OneHot Feature ({len(onehot_cols)}ê°œ): {', '.join(onehot_cols)}\n")
        f.write(f"Ordinal Feature ({len(ordinal_cols)}ê°œ): {', '.join(ordinal_cols)}\n")
        f.write(f"ì „ì²´ Feature ìˆ˜: {len(feature_names)}\n\n")
        
        # ì „ì²´ Feature ëª©ë¡ ì¶œë ¥ (ì‹ ê·œ í”¼ì³ í¬í•¨)
        f.write("ğŸ“‹ ì „ì²´ Feature ëª©ë¡ (ì‹ ê·œ ì¡°í•© íŠ¹ì„± í¬í•¨):\n")
        f.write("-" * 80 + "\n")
        
        # ì›ë³¸ íŠ¹ì„±ê³¼ ì‹ ê·œ íŠ¹ì„± êµ¬ë¶„
        original_features = get_feature_names(preprocessor, num_cols, onehot_cols, ordinal_cols)
        new_features = [f for f in feature_names if f not in original_features]
        
        f.write(f"ì›ë³¸ íŠ¹ì„± ìˆ˜: {len(original_features)}\n")
        f.write(f"ì‹ ê·œ ì¡°í•© íŠ¹ì„± ìˆ˜: {len(new_features)}\n\n")
        
        if new_features:
            f.write("ğŸ†• ì‹ ê·œ ì¡°í•© íŠ¹ì„± ëª©ë¡:\n")
            for i, feat in enumerate(new_features, 1):
                f.write(f"  {i:3d}. {feat}\n")
            f.write("\n")
        
        f.write("ì „ì²´ íŠ¹ì„± ëª©ë¡:\n")
        for i, feat in enumerate(feature_names, 1):
            is_new = "ğŸ†•" if feat in new_features else "  "
            f.write(f"  {i:3d}. {is_new} {feat}\n")
        f.write("\n")
        
        # ëª¨ë¸ë³„ ì„±ëŠ¥
        f.write("="*80 + "\n")
        f.write("ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ\n")
        f.write("="*80 + "\n\n")
        
        for name, model in models.items():
            y_pred = model.predict(X_val)
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            
            acc = accuracy_score(y_val, y_pred)
            auc = roc_auc_score(y_val, y_pred_proba)
            
            f.write(f"ğŸ”¹ {name} ëª¨ë¸\n")
            f.write(f"   Accuracy: {acc:.4f}\n")
            f.write(f"   ROC-AUC:  {auc:.4f}\n")
            f.write("\n   Classification Report:\n")
            f.write(classification_report(y_val, y_pred, target_names=['Not Paid', 'Paid']))
            f.write("\n")
        
        # Feature Importance - ëª¨ë“  íŠ¹ì„± ì €ì¥
        f.write("="*80 + "\n")
        f.write("ğŸ“ˆ ëª¨ë¸ë³„ Feature Importance (ì „ì²´ íŠ¹ì„±)\n")
        f.write("="*80 + "\n\n")
        
        for name, model in models.items():
            importance_dict = get_feature_importance(model, feature_names, name)
            sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
            
            f.write(f"ğŸ”¹ {name} - ì „ì²´ Features ({len(sorted_importance)}ê°œ):\n")
            f.write("-" * 80 + "\n")
            for i, (feature, importance) in enumerate(sorted_importance, 1):
                is_new = "ğŸ†•" if feature in new_features else "  "
                f.write(f"  {i:3d}. {is_new} {feature:50s} : {importance:10.4f}\n")
            f.write("\n")
    
    print(f"\nâœ… ëª¨ë¸ ë¶„ì„ ê²°ê³¼ê°€ '{filename}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   - ì „ì²´ íŠ¹ì„± ìˆ˜: {len(feature_names)}ê°œ")
    if new_features:
        print(f"   - ì‹ ê·œ ì¡°í•© íŠ¹ì„± ìˆ˜: {len(new_features)}ê°œ")


if __name__ == "__main__":

    df_train = df_train
    df_test = df_test
    df_sub = df_sub
    
    # eda(df_train, df_test, df_sub)

    df_array = [df_train, df_test]
    
    df_num_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
    df_cat_cols = df_train.select_dtypes(include=['object', 'category']).columns.tolist()
    
    target_col = 'loan_paid_back'
    
    # df_train, df_test = data_preprocessing(df_array, target_col, df_num_cols, df_cat_cols )
    
    df_train.head()
    df_test.head()
    
    preprocessor_list, models = main(df_array, target_col, df_num_cols, df_cat_cols)
    
    print("\n" + "="*80)
    print("ğŸ” ëª¨ë¸ ìƒì„¸ ë¶„ì„ ì‹œì‘")
    print("="*80)
     
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±
    X_test_processed_list = []
    
    for i in range(len(preprocessor_list)-1):
        preprocessor = preprocessor_list[i][4]  # preprocessor ê°ì²´
        X_test_processed = preprocessor.transform(df_test)
        X_test_processed_list.append(X_test_processed)
    
    # 2. Validation set ê°€ì ¸ì˜¤ê¸° (weights ê³„ì‚°ìš©)
    X_val_list = [preprocessor_list[i][1] for i in range(3)]  # [catboost, lgbm, xgb]
    y_val = preprocessor_list[0][3]  # ëª¨ë“  ëª¨ë¸ì˜ y_valì€ ë™ì¼

    # 3. Optimal weights ê³„ì‚°
    weights = find_optimal_weights(models, preprocessor_list)

    # 4. Ensemble ì˜ˆì¸¡
    _, y_pred_ensemble = ensemble_predict(
        models, 
        X_test_processed_list,  # ê° ëª¨ë¸ë³„ ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        weights
    )

    # 5. ì œì¶œ íŒŒì¼ ìƒì„±
    submission = pd.DataFrame({
        'id': df_sub['id'],
        'loan_paid_back': y_pred_ensemble
    })

    submission.to_csv('submission_ensemble.csv', index=False)
    df_confirm = pd.read_csv('submission_ensemble.csv')

    print(df_confirm.head())